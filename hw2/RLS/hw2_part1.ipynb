{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'train.csv')\n",
    "test_df = pd.read_csv(r'test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# train_df.info()\n",
    "categorical = list(train_df.select_dtypes('object').columns)\n",
    "# categorical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 1460 samples in the training data set and 80 features. There are 43 columns with the 'object' data type,\n",
    "meaning non-numeric categorical data. These features are contained in the \"categorical\" list. However, notice also that\n",
    "the 'MSSubClass' feature is numerical-categorical. Thus, there are actually 44 categorical features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I will select seven non-categorical features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# sns.pairplot(train_df[['SalePrice', 'LotArea', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'FullBath', '1stFlrSF', '2ndFlrSF']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plots we care about here are in row 1 (or column 1). There appears to be a correlation between sales price and:\n",
    "Overall Quality, 1st Floor Area, 2nd Floor Area, and some slight correlations with Year of Remodelling, and\n",
    "Number of Full Baths."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# sm.linear_model.OLS()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% optional\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "MSSubClass_encoded = pd.get_dummies(train_df[['MSSubClass']].astype(str))\n",
    "train_df_dropped = train_df.drop('Id', axis=1)\n",
    "df_encoded = pd.get_dummies(train_df_dropped)\n",
    "df_encoded = pd.concat([df_encoded, MSSubClass_encoded], axis=1).drop('MSSubClass', axis=1)\n",
    "# df_encoded.info(verbose=True, null_counts=True)\n",
    "# df_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Drop columns not useful to our model and perform one hot encoding.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "split = ms.train_test_split(df_encoded, train_size=0.8)\n",
    "train_split = split[0]\n",
    "test_split = split[1]\n",
    "# train_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Splitting data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "# encoder.fit(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% sklearn's encoder (not used)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = df_encoded.columns\n",
    "columns = df_encoded.drop(['SalePrice'], axis=1).columns\n",
    "train_split.columns[train_split.isna().any()].tolist()\n",
    "# test_split.columns[test_split.isna().any()].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Look for columns with null values\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting values to the mean or zeroes could highly skew the results of a regression model.\n",
    "I will use KNN to perform multivariate imputation, filling in the above columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Training the inputer with train split\n",
    "imputer_train = KNNImputer(n_neighbors=15, weights=\"uniform\")\n",
    "imputer_train.fit(train_split)\n",
    "train_split = pd.DataFrame(imputer_train.fit_transform(df_encoded), columns = all_columns)\n",
    "test_split = pd.DataFrame(imputer_train.fit_transform(test_split), columns = all_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% KNN inputation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n0       -0.247803 -0.207142     0.651479    -0.517200   1.050994   \n1        0.412273 -0.091886    -0.071836     2.179628   0.156734   \n2       -0.115788  0.073480     0.651479    -0.517200   0.984752   \n3       -0.467828 -0.096897     0.651479    -0.517200  -1.863632   \n4        0.588294  0.375148     1.374795    -0.517200   0.951632   \n...           ...       ...          ...          ...        ...   \n1455    -0.379818 -0.260560    -0.071836    -0.517200   0.918511   \n1456     0.632299  0.266407    -0.071836     0.381743   0.222975   \n1457    -0.203798 -0.147810     0.651479     3.078570  -1.002492   \n1458    -0.115788 -0.080160    -0.795151     0.381743  -0.704406   \n1459     0.192248 -0.058112    -0.795151     0.381743  -0.207594   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n0         0.878668    0.508709    0.575425   -0.288653  -0.944591  ...   \n1        -0.429577   -0.575571    1.171992   -0.288653  -0.641228  ...   \n2         0.830215    0.320620    0.092907   -0.288653  -0.301643  ...   \n3        -0.720298   -0.575571   -0.499274   -0.288653  -0.061670  ...   \n4         0.733308    1.360644    0.463568   -0.288653  -0.174865  ...   \n...            ...         ...         ...         ...        ...  ...   \n1455      0.733308   -0.575571   -0.973018   -0.288653   0.873321  ...   \n1456      0.151865    0.082742    0.759659    0.722112   0.049262  ...   \n1457      1.024029   -0.575571   -0.369871   -0.288653   0.701265  ...   \n1458      0.539493   -0.575571   -0.865548    6.092188  -1.284176  ...   \n1459     -0.962566   -0.575571    0.847389    1.509640  -0.976285  ...   \n\n      MSSubClass_30  MSSubClass_40  MSSubClass_45  MSSubClass_50  \\\n0         -0.222721      -0.052414      -0.091035      -0.330791   \n1         -0.222721      -0.052414      -0.091035      -0.330791   \n2         -0.222721      -0.052414      -0.091035      -0.330791   \n3         -0.222721      -0.052414      -0.091035      -0.330791   \n4         -0.222721      -0.052414      -0.091035      -0.330791   \n...             ...            ...            ...            ...   \n1455      -0.222721      -0.052414      -0.091035      -0.330791   \n1456      -0.222721      -0.052414      -0.091035      -0.330791   \n1457      -0.222721      -0.052414      -0.091035      -0.330791   \n1458      -0.222721      -0.052414      -0.091035      -0.330791   \n1459      -0.222721      -0.052414      -0.091035      -0.330791   \n\n      MSSubClass_60  MSSubClass_70  MSSubClass_75  MSSubClass_80  \\\n0          1.970518      -0.207020      -0.105263      -0.203395   \n1         -0.507481      -0.207020      -0.105263      -0.203395   \n2          1.970518      -0.207020      -0.105263      -0.203395   \n3         -0.507481       4.830459      -0.105263      -0.203395   \n4          1.970518      -0.207020      -0.105263      -0.203395   \n...             ...            ...            ...            ...   \n1455       1.970518      -0.207020      -0.105263      -0.203395   \n1456      -0.507481      -0.207020      -0.105263      -0.203395   \n1457      -0.507481       4.830459      -0.105263      -0.203395   \n1458      -0.507481      -0.207020      -0.105263      -0.203395   \n1459      -0.507481      -0.207020      -0.105263      -0.203395   \n\n      MSSubClass_85  MSSubClass_90  \n0         -0.117851      -0.192177  \n1         -0.117851      -0.192177  \n2         -0.117851      -0.192177  \n3         -0.117851      -0.192177  \n4         -0.117851      -0.192177  \n...             ...            ...  \n1455      -0.117851      -0.192177  \n1456      -0.117851      -0.192177  \n1457      -0.117851      -0.192177  \n1458      -0.117851      -0.192177  \n1459      -0.117851      -0.192177  \n\n[1460 rows x 302 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>...</th>\n      <th>MSSubClass_30</th>\n      <th>MSSubClass_40</th>\n      <th>MSSubClass_45</th>\n      <th>MSSubClass_50</th>\n      <th>MSSubClass_60</th>\n      <th>MSSubClass_70</th>\n      <th>MSSubClass_75</th>\n      <th>MSSubClass_80</th>\n      <th>MSSubClass_85</th>\n      <th>MSSubClass_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.247803</td>\n      <td>-0.207142</td>\n      <td>0.651479</td>\n      <td>-0.517200</td>\n      <td>1.050994</td>\n      <td>0.878668</td>\n      <td>0.508709</td>\n      <td>0.575425</td>\n      <td>-0.288653</td>\n      <td>-0.944591</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>1.970518</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.412273</td>\n      <td>-0.091886</td>\n      <td>-0.071836</td>\n      <td>2.179628</td>\n      <td>0.156734</td>\n      <td>-0.429577</td>\n      <td>-0.575571</td>\n      <td>1.171992</td>\n      <td>-0.288653</td>\n      <td>-0.641228</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.115788</td>\n      <td>0.073480</td>\n      <td>0.651479</td>\n      <td>-0.517200</td>\n      <td>0.984752</td>\n      <td>0.830215</td>\n      <td>0.320620</td>\n      <td>0.092907</td>\n      <td>-0.288653</td>\n      <td>-0.301643</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>1.970518</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.467828</td>\n      <td>-0.096897</td>\n      <td>0.651479</td>\n      <td>-0.517200</td>\n      <td>-1.863632</td>\n      <td>-0.720298</td>\n      <td>-0.575571</td>\n      <td>-0.499274</td>\n      <td>-0.288653</td>\n      <td>-0.061670</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>4.830459</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.588294</td>\n      <td>0.375148</td>\n      <td>1.374795</td>\n      <td>-0.517200</td>\n      <td>0.951632</td>\n      <td>0.733308</td>\n      <td>1.360644</td>\n      <td>0.463568</td>\n      <td>-0.288653</td>\n      <td>-0.174865</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>1.970518</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>-0.379818</td>\n      <td>-0.260560</td>\n      <td>-0.071836</td>\n      <td>-0.517200</td>\n      <td>0.918511</td>\n      <td>0.733308</td>\n      <td>-0.575571</td>\n      <td>-0.973018</td>\n      <td>-0.288653</td>\n      <td>0.873321</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>1.970518</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>0.632299</td>\n      <td>0.266407</td>\n      <td>-0.071836</td>\n      <td>0.381743</td>\n      <td>0.222975</td>\n      <td>0.151865</td>\n      <td>0.082742</td>\n      <td>0.759659</td>\n      <td>0.722112</td>\n      <td>0.049262</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>-0.203798</td>\n      <td>-0.147810</td>\n      <td>0.651479</td>\n      <td>3.078570</td>\n      <td>-1.002492</td>\n      <td>1.024029</td>\n      <td>-0.575571</td>\n      <td>-0.369871</td>\n      <td>-0.288653</td>\n      <td>0.701265</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>4.830459</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>-0.115788</td>\n      <td>-0.080160</td>\n      <td>-0.795151</td>\n      <td>0.381743</td>\n      <td>-0.704406</td>\n      <td>0.539493</td>\n      <td>-0.575571</td>\n      <td>-0.865548</td>\n      <td>6.092188</td>\n      <td>-1.284176</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>0.192248</td>\n      <td>-0.058112</td>\n      <td>-0.795151</td>\n      <td>0.381743</td>\n      <td>-0.207594</td>\n      <td>-0.962566</td>\n      <td>-0.575571</td>\n      <td>0.847389</td>\n      <td>1.509640</td>\n      <td>-0.976285</td>\n      <td>...</td>\n      <td>-0.222721</td>\n      <td>-0.052414</td>\n      <td>-0.091035</td>\n      <td>-0.330791</td>\n      <td>-0.507481</td>\n      <td>-0.207020</td>\n      <td>-0.105263</td>\n      <td>-0.203395</td>\n      <td>-0.117851</td>\n      <td>-0.192177</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 302 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the normalizer with train split\n",
    "normalize_train = StandardScaler().fit(train_split.drop(['SalePrice'], axis=1))\n",
    "\n",
    "train_norm = normalize_train.transform(train_split.drop(['SalePrice'], axis=1))\n",
    "test_norm = normalize_train.transform(test_split.drop(['SalePrice'], axis=1))\n",
    "\n",
    "train_norm = pd.DataFrame(train_norm, columns = columns)\n",
    "test_norm = pd.DataFrame(test_norm, columns = columns)\n",
    "train_norm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Normalize the test/train data sets\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X = train_norm\n",
    "Y = train_split['SalePrice']\n",
    "X_test = test_norm\n",
    "Y_test = test_split['SalePrice']\n",
    "\n",
    "X_non_norm = train_split.drop(['SalePrice'], axis=1)\n",
    "X_test_non_norm = test_split.drop(['SalePrice'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(302,)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = lm.LinearRegression().fit(X, Y)\n",
    "lin_pred = lin_reg.predict(X_test)\n",
    "# lin_reg.score(test_norm.drop(['SalePrice'], axis=1), test_norm['SalePrice'])\n",
    "r2_score(Y_test, lin_pred)\n",
    "np.shape(lin_reg.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Predicting values and finding R^2 value\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11}\n",
      "0.7405634361447293\n"
     ]
    },
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.003001  4.473412e-04         0.004501        0.000500   \n1        0.002501  5.000831e-04         0.004701        0.000640   \n2        0.003001  2.249236e-07         0.004801        0.000400   \n3        0.002701  4.585263e-04         0.005401        0.000490   \n4        0.003101  3.001217e-04         0.005601        0.000490   \n5        0.003101  3.004316e-04         0.005601        0.000664   \n6        0.003101  2.999392e-04         0.005801        0.000600   \n7        0.003301  4.584066e-04         0.005601        0.001429   \n8        0.002901  2.999545e-04         0.005301        0.000641   \n9        0.002901  3.001454e-04         0.005401        0.000490   \n10       0.003101  5.388717e-04         0.005701        0.000781   \n11       0.003001  4.473947e-04         0.005702        0.000641   \n12       0.003085  3.094812e-04         0.005501        0.000807   \n13       0.002911  3.052312e-04         0.005491        0.000490   \n\n   param_n_neighbors               params  split0_test_score  \\\n0                  1   {'n_neighbors': 1}           0.704337   \n1                  2   {'n_neighbors': 2}           0.760294   \n2                  3   {'n_neighbors': 3}           0.791678   \n3                  4   {'n_neighbors': 4}           0.779533   \n4                  5   {'n_neighbors': 5}           0.767779   \n5                  6   {'n_neighbors': 6}           0.773894   \n6                  7   {'n_neighbors': 7}           0.770276   \n7                  8   {'n_neighbors': 8}           0.810577   \n8                  9   {'n_neighbors': 9}           0.804290   \n9                 10  {'n_neighbors': 10}           0.799760   \n10                11  {'n_neighbors': 11}           0.802694   \n11                12  {'n_neighbors': 12}           0.798888   \n12                13  {'n_neighbors': 13}           0.794569   \n13                14  {'n_neighbors': 14}           0.796144   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n0            0.288652           0.673225           0.668503   \n1            0.597509           0.785232           0.744155   \n2            0.680672           0.789750           0.732312   \n3            0.716608           0.789691           0.720356   \n4            0.721353           0.793127           0.690670   \n5            0.783611           0.795534           0.700564   \n6            0.769669           0.790530           0.676201   \n7            0.764780           0.791389           0.670147   \n8            0.769589           0.791150           0.670639   \n9            0.760243           0.791905           0.686254   \n10           0.752803           0.796325           0.691095   \n11           0.747025           0.793641           0.695943   \n12           0.738115           0.786389           0.686157   \n13           0.736029           0.784709           0.683200   \n\n    split4_test_score  split5_test_score  split6_test_score  \\\n0            0.728969           0.596297           0.750835   \n1            0.724942           0.711895           0.783782   \n2            0.732995           0.743530           0.791826   \n3            0.731071           0.745167           0.763657   \n4            0.733361           0.774366           0.749560   \n5            0.712149           0.785216           0.754382   \n6            0.700273           0.789617           0.766473   \n7            0.695494           0.779921           0.763272   \n8            0.694627           0.787157           0.760536   \n9            0.700491           0.779018           0.766560   \n10           0.704504           0.777661           0.775733   \n11           0.702116           0.763405           0.778144   \n12           0.700082           0.760412           0.777863   \n13           0.697719           0.756924           0.775142   \n\n    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n0            0.632051           0.345203           0.638231         0.602630   \n1            0.755437           0.457308           0.693007         0.701356   \n2            0.754361           0.515357           0.750465         0.728295   \n3            0.782534           0.535011           0.747364         0.731099   \n4            0.783860           0.549151           0.765257         0.732849   \n5            0.779214           0.547689           0.769856         0.740211   \n6            0.773471           0.543436           0.772189         0.735213   \n7            0.792394           0.561254           0.773031         0.740226   \n8            0.782024           0.558202           0.768746         0.738696   \n9            0.784111           0.552897           0.765767         0.738701   \n10           0.780312           0.557722           0.766785         0.740563   \n11           0.781128           0.569559           0.766188         0.739604   \n12           0.779301           0.567476           0.768658         0.735902   \n13           0.783376           0.565936           0.772331         0.735151   \n\n    std_test_score  rank_test_score  \n0         0.149873               14  \n1         0.096509               13  \n2         0.078027               12  \n3         0.069802               11  \n4         0.067945               10  \n5         0.070802                3  \n6         0.073298                8  \n7         0.072813                2  \n8         0.072640                6  \n9         0.071381                5  \n10        0.070127                1  \n11        0.065726                4  \n12        0.065908                7  \n13        0.066852                9  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_n_neighbors</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>split5_test_score</th>\n      <th>split6_test_score</th>\n      <th>split7_test_score</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.003001</td>\n      <td>4.473412e-04</td>\n      <td>0.004501</td>\n      <td>0.000500</td>\n      <td>1</td>\n      <td>{'n_neighbors': 1}</td>\n      <td>0.704337</td>\n      <td>0.288652</td>\n      <td>0.673225</td>\n      <td>0.668503</td>\n      <td>0.728969</td>\n      <td>0.596297</td>\n      <td>0.750835</td>\n      <td>0.632051</td>\n      <td>0.345203</td>\n      <td>0.638231</td>\n      <td>0.602630</td>\n      <td>0.149873</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.002501</td>\n      <td>5.000831e-04</td>\n      <td>0.004701</td>\n      <td>0.000640</td>\n      <td>2</td>\n      <td>{'n_neighbors': 2}</td>\n      <td>0.760294</td>\n      <td>0.597509</td>\n      <td>0.785232</td>\n      <td>0.744155</td>\n      <td>0.724942</td>\n      <td>0.711895</td>\n      <td>0.783782</td>\n      <td>0.755437</td>\n      <td>0.457308</td>\n      <td>0.693007</td>\n      <td>0.701356</td>\n      <td>0.096509</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003001</td>\n      <td>2.249236e-07</td>\n      <td>0.004801</td>\n      <td>0.000400</td>\n      <td>3</td>\n      <td>{'n_neighbors': 3}</td>\n      <td>0.791678</td>\n      <td>0.680672</td>\n      <td>0.789750</td>\n      <td>0.732312</td>\n      <td>0.732995</td>\n      <td>0.743530</td>\n      <td>0.791826</td>\n      <td>0.754361</td>\n      <td>0.515357</td>\n      <td>0.750465</td>\n      <td>0.728295</td>\n      <td>0.078027</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002701</td>\n      <td>4.585263e-04</td>\n      <td>0.005401</td>\n      <td>0.000490</td>\n      <td>4</td>\n      <td>{'n_neighbors': 4}</td>\n      <td>0.779533</td>\n      <td>0.716608</td>\n      <td>0.789691</td>\n      <td>0.720356</td>\n      <td>0.731071</td>\n      <td>0.745167</td>\n      <td>0.763657</td>\n      <td>0.782534</td>\n      <td>0.535011</td>\n      <td>0.747364</td>\n      <td>0.731099</td>\n      <td>0.069802</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.003101</td>\n      <td>3.001217e-04</td>\n      <td>0.005601</td>\n      <td>0.000490</td>\n      <td>5</td>\n      <td>{'n_neighbors': 5}</td>\n      <td>0.767779</td>\n      <td>0.721353</td>\n      <td>0.793127</td>\n      <td>0.690670</td>\n      <td>0.733361</td>\n      <td>0.774366</td>\n      <td>0.749560</td>\n      <td>0.783860</td>\n      <td>0.549151</td>\n      <td>0.765257</td>\n      <td>0.732849</td>\n      <td>0.067945</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.003101</td>\n      <td>3.004316e-04</td>\n      <td>0.005601</td>\n      <td>0.000664</td>\n      <td>6</td>\n      <td>{'n_neighbors': 6}</td>\n      <td>0.773894</td>\n      <td>0.783611</td>\n      <td>0.795534</td>\n      <td>0.700564</td>\n      <td>0.712149</td>\n      <td>0.785216</td>\n      <td>0.754382</td>\n      <td>0.779214</td>\n      <td>0.547689</td>\n      <td>0.769856</td>\n      <td>0.740211</td>\n      <td>0.070802</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.003101</td>\n      <td>2.999392e-04</td>\n      <td>0.005801</td>\n      <td>0.000600</td>\n      <td>7</td>\n      <td>{'n_neighbors': 7}</td>\n      <td>0.770276</td>\n      <td>0.769669</td>\n      <td>0.790530</td>\n      <td>0.676201</td>\n      <td>0.700273</td>\n      <td>0.789617</td>\n      <td>0.766473</td>\n      <td>0.773471</td>\n      <td>0.543436</td>\n      <td>0.772189</td>\n      <td>0.735213</td>\n      <td>0.073298</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.003301</td>\n      <td>4.584066e-04</td>\n      <td>0.005601</td>\n      <td>0.001429</td>\n      <td>8</td>\n      <td>{'n_neighbors': 8}</td>\n      <td>0.810577</td>\n      <td>0.764780</td>\n      <td>0.791389</td>\n      <td>0.670147</td>\n      <td>0.695494</td>\n      <td>0.779921</td>\n      <td>0.763272</td>\n      <td>0.792394</td>\n      <td>0.561254</td>\n      <td>0.773031</td>\n      <td>0.740226</td>\n      <td>0.072813</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.002901</td>\n      <td>2.999545e-04</td>\n      <td>0.005301</td>\n      <td>0.000641</td>\n      <td>9</td>\n      <td>{'n_neighbors': 9}</td>\n      <td>0.804290</td>\n      <td>0.769589</td>\n      <td>0.791150</td>\n      <td>0.670639</td>\n      <td>0.694627</td>\n      <td>0.787157</td>\n      <td>0.760536</td>\n      <td>0.782024</td>\n      <td>0.558202</td>\n      <td>0.768746</td>\n      <td>0.738696</td>\n      <td>0.072640</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.002901</td>\n      <td>3.001454e-04</td>\n      <td>0.005401</td>\n      <td>0.000490</td>\n      <td>10</td>\n      <td>{'n_neighbors': 10}</td>\n      <td>0.799760</td>\n      <td>0.760243</td>\n      <td>0.791905</td>\n      <td>0.686254</td>\n      <td>0.700491</td>\n      <td>0.779018</td>\n      <td>0.766560</td>\n      <td>0.784111</td>\n      <td>0.552897</td>\n      <td>0.765767</td>\n      <td>0.738701</td>\n      <td>0.071381</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.003101</td>\n      <td>5.388717e-04</td>\n      <td>0.005701</td>\n      <td>0.000781</td>\n      <td>11</td>\n      <td>{'n_neighbors': 11}</td>\n      <td>0.802694</td>\n      <td>0.752803</td>\n      <td>0.796325</td>\n      <td>0.691095</td>\n      <td>0.704504</td>\n      <td>0.777661</td>\n      <td>0.775733</td>\n      <td>0.780312</td>\n      <td>0.557722</td>\n      <td>0.766785</td>\n      <td>0.740563</td>\n      <td>0.070127</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.003001</td>\n      <td>4.473947e-04</td>\n      <td>0.005702</td>\n      <td>0.000641</td>\n      <td>12</td>\n      <td>{'n_neighbors': 12}</td>\n      <td>0.798888</td>\n      <td>0.747025</td>\n      <td>0.793641</td>\n      <td>0.695943</td>\n      <td>0.702116</td>\n      <td>0.763405</td>\n      <td>0.778144</td>\n      <td>0.781128</td>\n      <td>0.569559</td>\n      <td>0.766188</td>\n      <td>0.739604</td>\n      <td>0.065726</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.003085</td>\n      <td>3.094812e-04</td>\n      <td>0.005501</td>\n      <td>0.000807</td>\n      <td>13</td>\n      <td>{'n_neighbors': 13}</td>\n      <td>0.794569</td>\n      <td>0.738115</td>\n      <td>0.786389</td>\n      <td>0.686157</td>\n      <td>0.700082</td>\n      <td>0.760412</td>\n      <td>0.777863</td>\n      <td>0.779301</td>\n      <td>0.567476</td>\n      <td>0.768658</td>\n      <td>0.735902</td>\n      <td>0.065908</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.002911</td>\n      <td>3.052312e-04</td>\n      <td>0.005491</td>\n      <td>0.000490</td>\n      <td>14</td>\n      <td>{'n_neighbors': 14}</td>\n      <td>0.796144</td>\n      <td>0.736029</td>\n      <td>0.784709</td>\n      <td>0.683200</td>\n      <td>0.697719</td>\n      <td>0.756924</td>\n      <td>0.775142</td>\n      <td>0.783376</td>\n      <td>0.565936</td>\n      <td>0.772331</td>\n      <td>0.735151</td>\n      <td>0.066852</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_reg = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors': np.arange(1, 15)}\n",
    "knn_grid_cv = ms.GridSearchCV(knn_reg, param_grid, cv=10)\n",
    "knn_grid_cv.fit(X, Y)\n",
    "print(knn_grid_cv.best_params_)\n",
    "print(knn_grid_cv.best_score_)\n",
    "display(pd.DataFrame(knn_grid_cv.cv_results_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It appears that 11 neighbours gives us the best score. However, given the standard error of about 0.07, a score of at least\n",
    "0.67 performs similarly. Thus, the \"rule-of-thumb\" best selection could be argued to be k=2 KNN with a score of 0.7014"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8505264801075464\n",
      "758.6209310344827\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = lm.RidgeCV(alphas=np.linspace(0.001,1000,30), cv=10)\n",
    "ridge_reg.fit(X, Y)\n",
    "print(ridge_reg.best_score_)\n",
    "print(ridge_reg.alpha_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Using RidgeCV\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 707.0716363636363}\n",
      "0.8505097456712031\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_alpha  \\\n0        0.007701      0.000641         0.001701        0.000458        0.001   \n1        0.007201      0.000600         0.001701        0.000458   101.011091   \n2        0.007101      0.000300         0.001701        0.000458   202.021182   \n3        0.007301      0.000458         0.001501        0.000500   303.031273   \n4        0.007101      0.000300         0.001801        0.000400   404.041364   \n..            ...           ...              ...             ...          ...   \n95       0.007015      0.000041         0.001901        0.000300  9595.959636   \n96       0.007101      0.000300         0.001801        0.000400  9696.969727   \n97       0.006901      0.000300         0.001400        0.000490  9797.979818   \n98       0.007402      0.000491         0.001401        0.000490  9898.989909   \n99       0.007101      0.000539         0.001601        0.000490      10000.0   \n\n                           params  split0_test_score  split1_test_score  \\\n0                {'alpha': 0.001}           0.882797           0.824154   \n1   {'alpha': 101.01109090909091}           0.908442           0.841937   \n2   {'alpha': 202.02118181818182}           0.915468           0.853634   \n3    {'alpha': 303.0312727272727}           0.918958           0.861450   \n4    {'alpha': 404.0413636363636}           0.920918           0.866878   \n..                            ...                ...                ...   \n95   {'alpha': 9595.959636363636}           0.807544           0.735987   \n96   {'alpha': 9696.969727272728}           0.806138           0.734420   \n97   {'alpha': 9797.979818181819}           0.804734           0.732859   \n98    {'alpha': 9898.98990909091}           0.803333           0.731305   \n99             {'alpha': 10000.0}           0.801934           0.729756   \n\n    split2_test_score  split3_test_score  split4_test_score  \\\n0            0.912537           0.751018           0.900222   \n1            0.917140           0.771243           0.903549   \n2            0.917034           0.778262           0.898969   \n3            0.916649           0.781929           0.894194   \n4            0.916232           0.784097           0.889546   \n..                ...                ...                ...   \n95           0.783840           0.687069           0.672809   \n96           0.782338           0.685824           0.671181   \n97           0.780840           0.684582           0.669561   \n98           0.779346           0.683342           0.667949   \n99           0.777856           0.682105           0.666346   \n\n    split5_test_score  split6_test_score  split7_test_score  \\\n0            0.589256           0.886591           0.895929   \n1            0.778636           0.893137           0.898473   \n2            0.815121           0.893655           0.897922   \n3            0.834656           0.892960           0.897239   \n4            0.846311           0.891740           0.896477   \n..                ...                ...                ...   \n95           0.715143           0.735236           0.762134   \n96           0.713599           0.733770           0.760684   \n97           0.712062           0.732308           0.759239   \n98           0.710532           0.730852           0.757797   \n99           0.709008           0.729401           0.756360   \n\n    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n0            0.420825          -1.254833         0.580850        0.630833   \n1            0.503665           0.899134         0.831536        0.120546   \n2            0.536410           0.897083         0.840356        0.110173   \n3            0.556682           0.895679         0.845040        0.103973   \n4            0.570754           0.894672         0.847762        0.099723   \n..                ...                ...              ...             ...   \n95           0.560058           0.768608         0.722843        0.067231   \n96           0.559009           0.767193         0.721416        0.067139   \n97           0.557961           0.765782         0.719993        0.067046   \n98           0.556914           0.764375         0.718575        0.066954   \n99           0.555869           0.762971         0.717161        0.066863   \n\n    rank_test_score  \n0               100  \n1                24  \n2                17  \n3                12  \n4                 9  \n..              ...  \n95               95  \n96               96  \n97               97  \n98               98  \n99               99  \n\n[100 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>split5_test_score</th>\n      <th>split6_test_score</th>\n      <th>split7_test_score</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007701</td>\n      <td>0.000641</td>\n      <td>0.001701</td>\n      <td>0.000458</td>\n      <td>0.001</td>\n      <td>{'alpha': 0.001}</td>\n      <td>0.882797</td>\n      <td>0.824154</td>\n      <td>0.912537</td>\n      <td>0.751018</td>\n      <td>0.900222</td>\n      <td>0.589256</td>\n      <td>0.886591</td>\n      <td>0.895929</td>\n      <td>0.420825</td>\n      <td>-1.254833</td>\n      <td>0.580850</td>\n      <td>0.630833</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.007201</td>\n      <td>0.000600</td>\n      <td>0.001701</td>\n      <td>0.000458</td>\n      <td>101.011091</td>\n      <td>{'alpha': 101.01109090909091}</td>\n      <td>0.908442</td>\n      <td>0.841937</td>\n      <td>0.917140</td>\n      <td>0.771243</td>\n      <td>0.903549</td>\n      <td>0.778636</td>\n      <td>0.893137</td>\n      <td>0.898473</td>\n      <td>0.503665</td>\n      <td>0.899134</td>\n      <td>0.831536</td>\n      <td>0.120546</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.007101</td>\n      <td>0.000300</td>\n      <td>0.001701</td>\n      <td>0.000458</td>\n      <td>202.021182</td>\n      <td>{'alpha': 202.02118181818182}</td>\n      <td>0.915468</td>\n      <td>0.853634</td>\n      <td>0.917034</td>\n      <td>0.778262</td>\n      <td>0.898969</td>\n      <td>0.815121</td>\n      <td>0.893655</td>\n      <td>0.897922</td>\n      <td>0.536410</td>\n      <td>0.897083</td>\n      <td>0.840356</td>\n      <td>0.110173</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.007301</td>\n      <td>0.000458</td>\n      <td>0.001501</td>\n      <td>0.000500</td>\n      <td>303.031273</td>\n      <td>{'alpha': 303.0312727272727}</td>\n      <td>0.918958</td>\n      <td>0.861450</td>\n      <td>0.916649</td>\n      <td>0.781929</td>\n      <td>0.894194</td>\n      <td>0.834656</td>\n      <td>0.892960</td>\n      <td>0.897239</td>\n      <td>0.556682</td>\n      <td>0.895679</td>\n      <td>0.845040</td>\n      <td>0.103973</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.007101</td>\n      <td>0.000300</td>\n      <td>0.001801</td>\n      <td>0.000400</td>\n      <td>404.041364</td>\n      <td>{'alpha': 404.0413636363636}</td>\n      <td>0.920918</td>\n      <td>0.866878</td>\n      <td>0.916232</td>\n      <td>0.784097</td>\n      <td>0.889546</td>\n      <td>0.846311</td>\n      <td>0.891740</td>\n      <td>0.896477</td>\n      <td>0.570754</td>\n      <td>0.894672</td>\n      <td>0.847762</td>\n      <td>0.099723</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.007015</td>\n      <td>0.000041</td>\n      <td>0.001901</td>\n      <td>0.000300</td>\n      <td>9595.959636</td>\n      <td>{'alpha': 9595.959636363636}</td>\n      <td>0.807544</td>\n      <td>0.735987</td>\n      <td>0.783840</td>\n      <td>0.687069</td>\n      <td>0.672809</td>\n      <td>0.715143</td>\n      <td>0.735236</td>\n      <td>0.762134</td>\n      <td>0.560058</td>\n      <td>0.768608</td>\n      <td>0.722843</td>\n      <td>0.067231</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.007101</td>\n      <td>0.000300</td>\n      <td>0.001801</td>\n      <td>0.000400</td>\n      <td>9696.969727</td>\n      <td>{'alpha': 9696.969727272728}</td>\n      <td>0.806138</td>\n      <td>0.734420</td>\n      <td>0.782338</td>\n      <td>0.685824</td>\n      <td>0.671181</td>\n      <td>0.713599</td>\n      <td>0.733770</td>\n      <td>0.760684</td>\n      <td>0.559009</td>\n      <td>0.767193</td>\n      <td>0.721416</td>\n      <td>0.067139</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.006901</td>\n      <td>0.000300</td>\n      <td>0.001400</td>\n      <td>0.000490</td>\n      <td>9797.979818</td>\n      <td>{'alpha': 9797.979818181819}</td>\n      <td>0.804734</td>\n      <td>0.732859</td>\n      <td>0.780840</td>\n      <td>0.684582</td>\n      <td>0.669561</td>\n      <td>0.712062</td>\n      <td>0.732308</td>\n      <td>0.759239</td>\n      <td>0.557961</td>\n      <td>0.765782</td>\n      <td>0.719993</td>\n      <td>0.067046</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.007402</td>\n      <td>0.000491</td>\n      <td>0.001401</td>\n      <td>0.000490</td>\n      <td>9898.989909</td>\n      <td>{'alpha': 9898.98990909091}</td>\n      <td>0.803333</td>\n      <td>0.731305</td>\n      <td>0.779346</td>\n      <td>0.683342</td>\n      <td>0.667949</td>\n      <td>0.710532</td>\n      <td>0.730852</td>\n      <td>0.757797</td>\n      <td>0.556914</td>\n      <td>0.764375</td>\n      <td>0.718575</td>\n      <td>0.066954</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.007101</td>\n      <td>0.000539</td>\n      <td>0.001601</td>\n      <td>0.000490</td>\n      <td>10000.0</td>\n      <td>{'alpha': 10000.0}</td>\n      <td>0.801934</td>\n      <td>0.729756</td>\n      <td>0.777856</td>\n      <td>0.682105</td>\n      <td>0.666346</td>\n      <td>0.709008</td>\n      <td>0.729401</td>\n      <td>0.756360</td>\n      <td>0.555869</td>\n      <td>0.762971</td>\n      <td>0.717161</td>\n      <td>0.066863</td>\n      <td>99</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg = lm.Ridge()\n",
    "param_grid = {'alpha': np.linspace(0.001,10000,100)}\n",
    "ridge_grid_cv = ms.GridSearchCV(ridge_reg, param_grid, cv=10)\n",
    "ridge_grid_cv.fit(X, Y)\n",
    "print(ridge_grid_cv.best_params_)\n",
    "print(ridge_grid_cv.best_score_)\n",
    "print(ridge_grid_cv.best_index_)\n",
    "ridge_cv_table = pd.DataFrame(ridge_grid_cv.cv_results_)\n",
    "ridge_cv_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Using GridSearch CV\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584074107463838\n",
      "mean_fit_time                            0.007202\n",
      "std_fit_time                               0.0006\n",
      "mean_score_time                          0.001701\n",
      "std_score_time                           0.000641\n",
      "param_alpha                           7272.727545\n",
      "params               {'alpha': 7272.727545454545}\n",
      "split0_test_score                        0.840509\n",
      "split1_test_score                        0.773738\n",
      "split2_test_score                        0.819431\n",
      "split3_test_score                        0.716242\n",
      "split4_test_score                        0.712863\n",
      "split5_test_score                        0.752594\n",
      "split6_test_score                         0.77045\n",
      "split7_test_score                        0.796494\n",
      "split8_test_score                        0.584314\n",
      "split9_test_score                        0.802137\n",
      "mean_test_score                          0.756877\n",
      "std_test_score                           0.069555\n",
      "rank_test_score                                72\n",
      "Name: 72, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "param_alpha        7171.717455\nmean_test_score       0.758408\nName: 71, dtype: object"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept = ridge_grid_cv.best_score_ - ridge_cv_table['std_test_score'].iloc[ridge_grid_cv.best_index_]\n",
    "print(accept)\n",
    "print(ridge_cv_table[(ridge_cv_table['mean_test_score'] <= accept) & (ridge_cv_table.index > ridge_grid_cv.best_index_)].iloc[0])\n",
    "ridge_cv_table[['param_alpha', 'mean_test_score']].iloc[71]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Standard Error\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our best score here is with lambda or alpha ~ 707.07 with 0.8505. The standard error is 0.0921. This means that our\n",
    "simplest model (higher lambda) is at index 71 (the lambda within our standard error threshold). This is lambda ~ 7172\n",
    "and CV score = 0.7584"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1632.6539795918368}\n",
      "0.8443541296515326\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = lm.Lasso()\n",
    "param_grid = {'alpha': np.linspace(0.001,20000,50)}\n",
    "lasso_grid_cv = ms.GridSearchCV(lasso_reg, param_grid, cv=10)\n",
    "lasso_grid_cv.fit(X, Y)\n",
    "print(lasso_grid_cv.best_params_)\n",
    "print(lasso_grid_cv.best_score_)\n",
    "print(lasso_grid_cv.best_index_)\n",
    "lasso_cv_table = pd.DataFrame(lasso_grid_cv.cv_results_)\n",
    "# lasso_cv_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7457931992421065\n",
      "mean_fit_time                             0.006601\n",
      "std_fit_time                               0.00049\n",
      "mean_score_time                           0.001601\n",
      "std_score_time                             0.00049\n",
      "param_alpha                           12653.061592\n",
      "params               {'alpha': 12653.061591836735}\n",
      "split0_test_score                          0.80166\n",
      "split1_test_score                         0.771215\n",
      "split2_test_score                         0.805111\n",
      "split3_test_score                         0.707488\n",
      "split4_test_score                         0.706631\n",
      "split5_test_score                         0.715163\n",
      "split6_test_score                         0.764257\n",
      "split7_test_score                         0.766628\n",
      "split8_test_score                         0.596848\n",
      "split9_test_score                         0.796461\n",
      "mean_test_score                           0.743146\n",
      "std_test_score                            0.060566\n",
      "rank_test_score                                 32\n",
      "Name: 31, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "param_alpha        12244.898347\nmean_test_score         0.74699\nName: 30, dtype: object"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept = lasso_grid_cv.best_score_ - lasso_cv_table['std_test_score'].iloc[lasso_grid_cv.best_index_]\n",
    "print(accept)\n",
    "print(lasso_cv_table[(lasso_cv_table['mean_test_score'] <= accept) & (lasso_cv_table.index > lasso_grid_cv.best_index_)].iloc[0])\n",
    "lasso_cv_table[['param_alpha', 'mean_test_score']].iloc[30]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Standard Error\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our best score here is with lambda or alpha ~ 1632.65 with 0.8444. The standard error is 0.0986. This means that our\n",
    "simplest model (higher lambda) is at index 30 (the lambda within our standard error threshold).\n",
    "This is lambda ~ 12245 and CV score = 0.7470"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5740162171877558\n",
      "0.6390221064393009\n",
      "[ 0.86387649  0.80127488  0.91110944  0.74827339  0.90051782  0.62523891\n",
      "  0.88577184  0.89588169  0.39476086 -1.28654315]\n"
     ]
    }
   ],
   "source": [
    "lin_reg_cv = lm.LinearRegression()\n",
    "cv_scores = cross_val_score(lin_reg_cv, X_non_norm, Y, cv=10)\n",
    "print(np.mean(cv_scores))\n",
    "print(np.std(cv_scores))\n",
    "print(cv_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% BSR on non-normalized data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "v = np.linalg.inv(X.T.dot(X).values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def sse_calc(y, y_hat):\n",
    "    return np.sum(np.square(y - y_hat))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def z_calc(beta, n, k, v_j, sse):\n",
    "    sigma = np.sqrt(1/(n-k-1) * sse)\n",
    "    return beta/(sigma * np.sqrt(v_j))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 302)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.split(X)\n",
    "n_fold = 1\n",
    "p = len(X.columns)\n",
    "z_all = np.empty((0,p))\n",
    "print(np.shape(z_all))\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    z_row = []\n",
    "    train_fold_X = X_non_norm.iloc[train_index]\n",
    "    train_fold_Y = Y.iloc[train_index]\n",
    "\n",
    "    test_fold_X = X_non_norm.iloc[test_index]\n",
    "    test_fold_Y = Y.iloc[test_index]\n",
    "\n",
    "    lin_reg_fold = lm.LinearRegression().fit(train_fold_X, train_fold_Y)\n",
    "    pred_fold = lin_reg_fold.predict(test_fold_X)\n",
    "\n",
    "    n = len(train_fold_X) ### should be test length\n",
    "    k = len(train_fold_X.columns)\n",
    "    xtx = train_fold_X.T.dot(train_fold_X).values\n",
    "    v = np.linalg.pinv(xtx)\n",
    "\n",
    "    sse = sse_calc(test_fold_Y, pred_fold)\n",
    "    beta = lin_reg_fold.coef_\n",
    "\n",
    "    for j in range(len(beta)):\n",
    "        v_j = v[j,j]\n",
    "        b_j = beta[j]\n",
    "        z_j = z_calc(b_j, n, k, v_j, sse)\n",
    "        z_row.append(z_j)\n",
    "    z_all = np.append(z_all, np.array([z_row]), axis=0)\n",
    "    n_fold += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "       LotFrontage    LotArea  OverallQual  OverallCond  YearBuilt  \\\ncount    10.000000  10.000000    10.000000    10.000000  10.000000   \nmean      2.240815   9.783085    10.590821    10.885915   6.528354   \nstd       0.874715   3.586738     4.698628     4.574634   2.702237   \nmin       0.935428   3.379450     3.387678     3.159908   2.055800   \n25%       1.489418   8.443376     7.628545     8.645514   5.194523   \n50%       2.407223  10.320636    10.656001    11.082886   6.506347   \n75%       2.720762  11.578973    14.410943    15.190964   8.735547   \nmax       3.594324  14.488166    16.487793    15.677444   9.811755   \n\n       YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\ncount     10.000000   10.000000    9.000000    9.000000   9.000000  ...   \nmean       3.046017    6.650530    9.916069    2.774523  -1.108890  ...   \nstd        1.043014    3.214977    2.948861    1.094164   0.798098  ...   \nmin        1.176236    2.195324    4.806823    0.734019  -2.323435  ...   \n25%        2.306489    4.210880    8.196488    2.506297  -1.816513  ...   \n50%        3.255468    6.639944    9.969461    2.938253  -0.793354  ...   \n75%        3.959173    9.075880   11.500695    3.381540  -0.563810  ...   \nmax        4.309497   11.292743   14.507054    4.183681  -0.033292  ...   \n\n       MSSubClass_30  MSSubClass_40  MSSubClass_45  MSSubClass_50  \\\ncount      10.000000      10.000000      10.000000      10.000000   \nmean        1.046747       0.091051      -0.181840       0.306769   \nstd         0.634400       0.436292       0.543579       0.326913   \nmin         0.180531      -0.337273      -1.139263      -0.340971   \n25%         0.568305      -0.189853      -0.454888       0.145715   \n50%         0.991280      -0.049502      -0.259856       0.356210   \n75%         1.565854       0.109978       0.213523       0.521070   \nmax         2.059364       0.916599       0.682041       0.773034   \n\n       MSSubClass_60  MSSubClass_70  MSSubClass_75  MSSubClass_80  \\\ncount      10.000000      10.000000      10.000000      10.000000   \nmean        1.156668       1.457959      -0.879254      -0.712504   \nstd         0.695981       0.869636       1.732635       0.410773   \nmin         0.255046       0.354799      -3.327166      -1.629903   \n25%         0.596242       0.799867      -2.226205      -0.821744   \n50%         1.072019       1.188252      -0.775491      -0.622470   \n75%         1.496508       2.137568       0.305592      -0.450598   \nmax         2.433606       2.972476       1.761751      -0.301846   \n\n       MSSubClass_85  MSSubClass_90  \ncount      10.000000      10.000000  \nmean       -0.883752       0.010241  \nstd         0.459427       0.209635  \nmin        -1.915466      -0.333099  \n25%        -1.168287      -0.065163  \n50%        -0.663907      -0.016944  \n75%        -0.535978       0.051123  \nmax        -0.515653       0.476572  \n\n[8 rows x 302 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>...</th>\n      <th>MSSubClass_30</th>\n      <th>MSSubClass_40</th>\n      <th>MSSubClass_45</th>\n      <th>MSSubClass_50</th>\n      <th>MSSubClass_60</th>\n      <th>MSSubClass_70</th>\n      <th>MSSubClass_75</th>\n      <th>MSSubClass_80</th>\n      <th>MSSubClass_85</th>\n      <th>MSSubClass_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>...</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.240815</td>\n      <td>9.783085</td>\n      <td>10.590821</td>\n      <td>10.885915</td>\n      <td>6.528354</td>\n      <td>3.046017</td>\n      <td>6.650530</td>\n      <td>9.916069</td>\n      <td>2.774523</td>\n      <td>-1.108890</td>\n      <td>...</td>\n      <td>1.046747</td>\n      <td>0.091051</td>\n      <td>-0.181840</td>\n      <td>0.306769</td>\n      <td>1.156668</td>\n      <td>1.457959</td>\n      <td>-0.879254</td>\n      <td>-0.712504</td>\n      <td>-0.883752</td>\n      <td>0.010241</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.874715</td>\n      <td>3.586738</td>\n      <td>4.698628</td>\n      <td>4.574634</td>\n      <td>2.702237</td>\n      <td>1.043014</td>\n      <td>3.214977</td>\n      <td>2.948861</td>\n      <td>1.094164</td>\n      <td>0.798098</td>\n      <td>...</td>\n      <td>0.634400</td>\n      <td>0.436292</td>\n      <td>0.543579</td>\n      <td>0.326913</td>\n      <td>0.695981</td>\n      <td>0.869636</td>\n      <td>1.732635</td>\n      <td>0.410773</td>\n      <td>0.459427</td>\n      <td>0.209635</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.935428</td>\n      <td>3.379450</td>\n      <td>3.387678</td>\n      <td>3.159908</td>\n      <td>2.055800</td>\n      <td>1.176236</td>\n      <td>2.195324</td>\n      <td>4.806823</td>\n      <td>0.734019</td>\n      <td>-2.323435</td>\n      <td>...</td>\n      <td>0.180531</td>\n      <td>-0.337273</td>\n      <td>-1.139263</td>\n      <td>-0.340971</td>\n      <td>0.255046</td>\n      <td>0.354799</td>\n      <td>-3.327166</td>\n      <td>-1.629903</td>\n      <td>-1.915466</td>\n      <td>-0.333099</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.489418</td>\n      <td>8.443376</td>\n      <td>7.628545</td>\n      <td>8.645514</td>\n      <td>5.194523</td>\n      <td>2.306489</td>\n      <td>4.210880</td>\n      <td>8.196488</td>\n      <td>2.506297</td>\n      <td>-1.816513</td>\n      <td>...</td>\n      <td>0.568305</td>\n      <td>-0.189853</td>\n      <td>-0.454888</td>\n      <td>0.145715</td>\n      <td>0.596242</td>\n      <td>0.799867</td>\n      <td>-2.226205</td>\n      <td>-0.821744</td>\n      <td>-1.168287</td>\n      <td>-0.065163</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.407223</td>\n      <td>10.320636</td>\n      <td>10.656001</td>\n      <td>11.082886</td>\n      <td>6.506347</td>\n      <td>3.255468</td>\n      <td>6.639944</td>\n      <td>9.969461</td>\n      <td>2.938253</td>\n      <td>-0.793354</td>\n      <td>...</td>\n      <td>0.991280</td>\n      <td>-0.049502</td>\n      <td>-0.259856</td>\n      <td>0.356210</td>\n      <td>1.072019</td>\n      <td>1.188252</td>\n      <td>-0.775491</td>\n      <td>-0.622470</td>\n      <td>-0.663907</td>\n      <td>-0.016944</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.720762</td>\n      <td>11.578973</td>\n      <td>14.410943</td>\n      <td>15.190964</td>\n      <td>8.735547</td>\n      <td>3.959173</td>\n      <td>9.075880</td>\n      <td>11.500695</td>\n      <td>3.381540</td>\n      <td>-0.563810</td>\n      <td>...</td>\n      <td>1.565854</td>\n      <td>0.109978</td>\n      <td>0.213523</td>\n      <td>0.521070</td>\n      <td>1.496508</td>\n      <td>2.137568</td>\n      <td>0.305592</td>\n      <td>-0.450598</td>\n      <td>-0.535978</td>\n      <td>0.051123</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.594324</td>\n      <td>14.488166</td>\n      <td>16.487793</td>\n      <td>15.677444</td>\n      <td>9.811755</td>\n      <td>4.309497</td>\n      <td>11.292743</td>\n      <td>14.507054</td>\n      <td>4.183681</td>\n      <td>-0.033292</td>\n      <td>...</td>\n      <td>2.059364</td>\n      <td>0.916599</td>\n      <td>0.682041</td>\n      <td>0.773034</td>\n      <td>2.433606</td>\n      <td>2.972476</td>\n      <td>1.761751</td>\n      <td>-0.301846</td>\n      <td>-0.515653</td>\n      <td>0.476572</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 302 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_all = pd.DataFrame(z_all, columns=columns)\n",
    "z_all.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# z_all.info(verbose=True, show_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "array = np.empty((0,3))\n",
    "\n",
    "array = np.append(array, np.array([[1,3,5]]), axis=0)\n",
    "array = np.append(array, np.array([[2,4,6]]), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 303)\n",
      "(292, 302)\n",
      "(292, 303)\n"
     ]
    }
   ],
   "source": [
    "X_sm = sm.add_constant(X)\n",
    "sm_OLS_model = OLS(Y,X_sm)\n",
    "result_sm = sm_OLS_model.fit()\n",
    "type(result_sm.tvalues)\n",
    "\n",
    "X_test_sm = sm.add_constant(X_test, has_constant='add')\n",
    "Y_sm_pred = result_sm.predict(sm.add_constant(X_test_sm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9344011723484195"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test, Y_sm_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "const            305.889535\nLotFrontage        1.345830\nLotArea            6.102238\nOverallQual        6.354396\nOverallCond        6.651298\n                    ...    \nMSSubClass_70      1.330307\nMSSubClass_75     -1.104664\nMSSubClass_80     -0.862262\nMSSubClass_85     -1.240249\nMSSubClass_90     -0.874659\nLength: 303, dtype: float64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sm.summary()\n",
    "result_sm.tvalues"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       0.079417      0.006169         0.002101          0.0003   \n\n  param_fit_intercept                   params  split0_test_score  \\\n0                True  {'fit_intercept': True}      -1.098781e+25   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n0      -3.402445e+25      -1.032912e+24      -7.858075e+24      -4.396432e+24   \n\n   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n0      -1.154353e+24      -1.304823e+24      -2.456593e+24      -1.798149e+25   \n\n   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n0      -1.993961e+26    -2.805930e+25    5.794696e+25                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_fit_intercept</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>split5_test_score</th>\n      <th>split6_test_score</th>\n      <th>split7_test_score</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.079417</td>\n      <td>0.006169</td>\n      <td>0.002101</td>\n      <td>0.0003</td>\n      <td>True</td>\n      <td>{'fit_intercept': True}</td>\n      <td>-1.098781e+25</td>\n      <td>-3.402445e+25</td>\n      <td>-1.032912e+24</td>\n      <td>-7.858075e+24</td>\n      <td>-4.396432e+24</td>\n      <td>-1.154353e+24</td>\n      <td>-1.304823e+24</td>\n      <td>-2.456593e+24</td>\n      <td>-1.798149e+25</td>\n      <td>-1.993961e+26</td>\n      <td>-2.805930e+25</td>\n      <td>5.794696e+25</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSR_reg = lm.LinearRegression()\n",
    "param_grid = {'fit_intercept': [True]}\n",
    "BSR_grid_cv = ms.GridSearchCV(BSR_reg, param_grid, cv=10)\n",
    "BSR_grid_cv.fit(X, Y)\n",
    "pd.DataFrame(BSR_grid_cv.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       0.072759       0.00133         0.001701        0.000458   \n\n  param_fit_intercept                   params  split0_test_score  \\\n0                True  {'fit_intercept': True}           0.863876   \n\n   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n0           0.801275           0.911109           0.748273           0.900518   \n\n   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n0           0.625239           0.885772           0.895882           0.394761   \n\n   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n0          -1.286543         0.574016        0.639022                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_fit_intercept</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>split5_test_score</th>\n      <th>split6_test_score</th>\n      <th>split7_test_score</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.072759</td>\n      <td>0.00133</td>\n      <td>0.001701</td>\n      <td>0.000458</td>\n      <td>True</td>\n      <td>{'fit_intercept': True}</td>\n      <td>0.863876</td>\n      <td>0.801275</td>\n      <td>0.911109</td>\n      <td>0.748273</td>\n      <td>0.900518</td>\n      <td>0.625239</td>\n      <td>0.885772</td>\n      <td>0.895882</td>\n      <td>0.394761</td>\n      <td>-1.286543</td>\n      <td>0.574016</td>\n      <td>0.639022</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSR_reg = lm.LinearRegression()\n",
    "param_grid = {'fit_intercept': [True]}\n",
    "BSR_grid_cv = ms.GridSearchCV(BSR_reg, param_grid, cv=10)\n",
    "BSR_grid_cv.fit(X_non_norm, Y)\n",
    "BSR_results = pd.DataFrame(BSR_grid_cv.cv_results_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}